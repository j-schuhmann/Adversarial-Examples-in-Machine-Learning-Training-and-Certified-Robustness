{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from util import mnist_binary_data_and_preprocessing,mnist_binary_all_data_and_preprocessing\n",
    "from classified_robustness import compute_bounds,test_iterations_influence,compare2models_trained,compute_delta_test_set\n",
    "from adversarial_training import training_model,pgd_adversarial_training,fgsm_adversarial_training\n",
    "from models import ground_model_delta_experiments1,ground_model_delta_experiments2,ground_model_delta_experiments3,ground_model_delta_experiments4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test=mnist_binary_all_data_and_preprocessing()\n",
    "input_shape = (28, 28, 1)\n",
    "learning_rate =0.001\n",
    "batch_size = 32 \n",
    "loss_object = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "\n",
    "normal1=training_model(ground_model_delta_experiments1(input_shape),tf.keras.optimizers.Adam(learning_rate=learning_rate),loss_object,30,batch_size,x_train[:1000], y_train[:1000], x_test[:1000], y_test[:1000])\n",
    "normal2=training_model(ground_model_delta_experiments2(input_shape),tf.keras.optimizers.Adam(learning_rate=learning_rate),loss_object,30,batch_size,x_train[:1000], y_train[:1000], x_test[:1000], y_test[:1000])\n",
    "normal3=training_model(ground_model_delta_experiments3(input_shape),tf.keras.optimizers.Adam(learning_rate=learning_rate),loss_object,30,batch_size,x_train[:1000], y_train[:1000], x_test[:1000], y_test[:1000])\n",
    "normal4=training_model(ground_model_delta_experiments4(input_shape),tf.keras.optimizers.Adam(learning_rate=learning_rate),loss_object,30,batch_size,x_train[:1000], y_train[:1000], x_test[:1000], y_test[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Loss: 8.780762672424316\n",
      "Epoch 2/30\n",
      "Loss: 8.222468376159668\n",
      "Epoch 3/30\n",
      "Loss: 8.107665061950684\n",
      "Epoch 4/30\n",
      "Loss: 8.064693450927734\n",
      "Epoch 5/30\n",
      "Loss: 7.992757320404053\n",
      "Epoch 6/30\n",
      "Loss: 7.728573322296143\n",
      "Epoch 7/30\n",
      "Loss: 7.567165374755859\n",
      "Epoch 8/30\n",
      "Loss: 7.456969261169434\n",
      "Epoch 9/30\n",
      "Loss: 7.478005409240723\n",
      "Epoch 10/30\n",
      "Loss: 7.0014567375183105\n",
      "Epoch 11/30\n",
      "Loss: 6.9727888107299805\n",
      "Epoch 12/30\n",
      "Loss: 6.935755252838135\n",
      "Epoch 13/30\n",
      "Loss: 6.632124900817871\n",
      "Epoch 14/30\n",
      "Loss: 6.48676061630249\n",
      "Epoch 15/30\n",
      "Loss: 6.39673376083374\n",
      "Epoch 16/30\n",
      "Loss: 6.225387096405029\n",
      "Epoch 17/30\n",
      "Loss: 6.025397300720215\n",
      "Epoch 18/30\n",
      "Loss: 6.2461934089660645\n",
      "Epoch 19/30\n",
      "Loss: 5.742197036743164\n",
      "Epoch 20/30\n",
      "Loss: 5.685634613037109\n",
      "Epoch 21/30\n",
      "Loss: 5.443192481994629\n",
      "Epoch 22/30\n",
      "Loss: 5.318732261657715\n",
      "Epoch 23/30\n",
      "Loss: 5.143219470977783\n",
      "Epoch 24/30\n",
      "Loss: 5.1550445556640625\n",
      "Epoch 25/30\n",
      "Loss: 4.946073532104492\n",
      "Epoch 26/30\n",
      "Loss: 4.932755947113037\n",
      "Epoch 27/30\n",
      "Loss: 4.631129264831543\n",
      "Epoch 28/30\n",
      "Loss: 4.527586460113525\n",
      "Epoch 29/30\n",
      "Loss: 4.418254375457764\n",
      "Epoch 30/30\n",
      "Loss: 4.423068523406982\n",
      "Epoch 1/30\n",
      "Loss: 27.04277801513672\n",
      "Epoch 2/30\n",
      "Loss: 18.918743133544922\n",
      "Epoch 3/30\n",
      "Loss: 16.313232421875\n",
      "Epoch 4/30\n",
      "Loss: 14.668401718139648\n",
      "Epoch 5/30\n",
      "Loss: 13.080120086669922\n",
      "Epoch 6/30\n",
      "Loss: 12.39129638671875\n",
      "Epoch 7/30\n",
      "Loss: 11.798267364501953\n",
      "Epoch 8/30\n",
      "Loss: 10.983837127685547\n",
      "Epoch 9/30\n",
      "Loss: 10.70618724822998\n",
      "Epoch 10/30\n",
      "Loss: 10.096267700195312\n",
      "Epoch 11/30\n",
      "Loss: 9.881962776184082\n",
      "Epoch 12/30\n",
      "Loss: 9.506314277648926\n",
      "Epoch 13/30\n",
      "Loss: 9.611381530761719\n",
      "Epoch 14/30\n",
      "Loss: 8.874663352966309\n",
      "Epoch 15/30\n",
      "Loss: 8.473549842834473\n",
      "Epoch 16/30\n",
      "Loss: 8.169332504272461\n",
      "Epoch 17/30\n",
      "Loss: 8.134897232055664\n",
      "Epoch 18/30\n",
      "Loss: 7.153417587280273\n",
      "Epoch 19/30\n",
      "Loss: 7.0746283531188965\n",
      "Epoch 20/30\n",
      "Loss: 6.889172077178955\n",
      "Epoch 21/30\n",
      "Loss: 6.442902565002441\n",
      "Epoch 22/30\n",
      "Loss: 6.249086380004883\n",
      "Epoch 23/30\n",
      "Loss: 5.5658721923828125\n",
      "Epoch 24/30\n",
      "Loss: 5.292247295379639\n",
      "Epoch 25/30\n",
      "Loss: 4.941562652587891\n",
      "Epoch 26/30\n",
      "Loss: 4.6575517654418945\n",
      "Epoch 27/30\n",
      "Loss: 4.346339225769043\n",
      "Epoch 28/30\n",
      "Loss: 4.133005619049072\n",
      "Epoch 29/30\n",
      "Loss: 4.010436534881592\n",
      "Epoch 30/30\n",
      "Loss: 3.716296434402466\n",
      "Epoch 1/30\n",
      "Loss: 33.63127136230469\n",
      "Epoch 2/30\n",
      "Loss: 22.99755096435547\n",
      "Epoch 3/30\n",
      "Loss: 17.590452194213867\n",
      "Epoch 4/30\n",
      "Loss: 13.674623489379883\n",
      "Epoch 5/30\n",
      "Loss: 12.905240058898926\n",
      "Epoch 6/30\n",
      "Loss: 11.777873992919922\n",
      "Epoch 7/30\n",
      "Loss: 10.561189651489258\n",
      "Epoch 8/30\n",
      "Loss: 10.944583892822266\n",
      "Epoch 9/30\n",
      "Loss: 9.916707992553711\n",
      "Epoch 10/30\n",
      "Loss: 10.218062400817871\n",
      "Epoch 11/30\n",
      "Loss: 8.421274185180664\n",
      "Epoch 12/30\n",
      "Loss: 7.662989139556885\n",
      "Epoch 13/30\n",
      "Loss: 6.664447784423828\n",
      "Epoch 14/30\n",
      "Loss: 6.1616926193237305\n",
      "Epoch 15/30\n",
      "Loss: 5.487272262573242\n",
      "Epoch 16/30\n",
      "Loss: 4.519713401794434\n",
      "Epoch 17/30\n",
      "Loss: 4.230944633483887\n",
      "Epoch 18/30\n",
      "Loss: 3.4212591648101807\n",
      "Epoch 19/30\n",
      "Loss: 2.7953052520751953\n",
      "Epoch 20/30\n",
      "Loss: 2.6286885738372803\n",
      "Epoch 21/30\n",
      "Loss: 1.9726942777633667\n",
      "Epoch 22/30\n",
      "Loss: 1.6469542980194092\n",
      "Epoch 23/30\n",
      "Loss: 1.4515198469161987\n",
      "Epoch 24/30\n",
      "Loss: 1.0676158666610718\n",
      "Epoch 25/30\n",
      "Loss: 0.8395711183547974\n",
      "Epoch 26/30\n",
      "Loss: 0.6635830998420715\n",
      "Epoch 27/30\n",
      "Loss: 0.5171290040016174\n",
      "Epoch 28/30\n",
      "Loss: 0.4583342969417572\n",
      "Epoch 29/30\n",
      "Loss: 0.3925236165523529\n",
      "Epoch 30/30\n",
      "Loss: 0.32732176780700684\n",
      "Epoch 1/30\n",
      "Loss: 1.8828632831573486\n",
      "Epoch 2/30\n",
      "Loss: 1.8804410696029663\n",
      "Epoch 3/30\n",
      "Loss: 1.8694159984588623\n",
      "Epoch 4/30\n",
      "Loss: 1.8638012409210205\n",
      "Epoch 5/30\n",
      "Loss: 1.8452742099761963\n",
      "Epoch 6/30\n",
      "Loss: 1.8104615211486816\n",
      "Epoch 7/30\n",
      "Loss: 1.7992422580718994\n",
      "Epoch 8/30\n",
      "Loss: 1.7526775598526\n",
      "Epoch 9/30\n",
      "Loss: 2.050976276397705\n",
      "Epoch 10/30\n",
      "Loss: 2.0917630195617676\n",
      "Epoch 11/30\n",
      "Loss: 1.826200008392334\n",
      "Epoch 12/30\n",
      "Loss: 1.9762409925460815\n",
      "Epoch 13/30\n",
      "Loss: 2.712656021118164\n",
      "Epoch 14/30\n",
      "Loss: 2.859872579574585\n",
      "Epoch 15/30\n",
      "Loss: 1.597961664199829\n",
      "Epoch 16/30\n",
      "Loss: 1.3489148616790771\n",
      "Epoch 17/30\n",
      "Loss: 1.6777690649032593\n",
      "Epoch 18/30\n",
      "Loss: 1.7914273738861084\n",
      "Epoch 19/30\n",
      "Loss: 1.7092589139938354\n",
      "Epoch 20/30\n",
      "Loss: 1.0722662210464478\n",
      "Epoch 21/30\n",
      "Loss: 0.8959077596664429\n",
      "Epoch 22/30\n",
      "Loss: 0.8244848847389221\n",
      "Epoch 23/30\n",
      "Loss: 0.7546496391296387\n",
      "Epoch 24/30\n",
      "Loss: 0.6137880086898804\n",
      "Epoch 25/30\n",
      "Loss: 0.6477819681167603\n",
      "Epoch 26/30\n",
      "Loss: 0.6123853325843811\n",
      "Epoch 27/30\n",
      "Loss: 0.5042359828948975\n",
      "Epoch 28/30\n",
      "Loss: 0.4554002583026886\n",
      "Epoch 29/30\n",
      "Loss: 0.42942264676094055\n",
      "Epoch 30/30\n",
      "Loss: 0.3589574098587036\n"
     ]
    }
   ],
   "source": [
    "normal1.train()\n",
    "normal2.train()\n",
    "normal3.train()\n",
    "normal4.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Gemeinschafts-PC\\Desktop\\Jonas\\Masterarbeit\\Implementation\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step   \n",
      "Accuracy on test set: 0.822\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Accuracy on test set: 0.456\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Accuracy on test set: 0.456\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "Accuracy on test set: 0.456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.456"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal1.evaluate_model_test_set(robustness_experiment=True)\n",
    "normal2.evaluate_model_test_set(robustness_experiment=True)\n",
    "normal3.evaluate_model_test_set(robustness_experiment=True)\n",
    "normal4.evaluate_model_test_set(robustness_experiment=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    }
   ],
   "source": [
    "def custom_sign(x):\n",
    "        return tf.sign(x)\n",
    "\n",
    "def model_with_sign(model):\n",
    "    model_with_sign = tf.keras.models.Sequential([\n",
    "        model,                       \n",
    "        tf.keras.layers.Lambda(custom_sign)          \n",
    "    ])\n",
    "    return model_with_sign\n",
    "\n",
    "\n",
    "x_tests = x_test[:1000]\n",
    "y_tests = y_test[:1000]\n",
    "\n",
    "preds1 = model_with_sign(normal1.model).predict(x_tests).flatten()\n",
    "preds2 = model_with_sign(normal2.model).predict(x_tests).flatten()\n",
    "preds3 = model_with_sign(normal3.model).predict(x_tests).flatten()\n",
    "preds4 = model_with_sign(normal4.model).predict(x_tests).flatten()\n",
    "\n",
    "\n",
    "correct_mask = (preds1 == y_tests)  (preds2 == y_tests) & (preds3 == y_tests) & (preds4 == y_tests)\n",
    "\n",
    "# Get the correctly classified images\n",
    "correct_images = x_tests[correct_mask]\n",
    "correct_labels = y_tests[correct_mask]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
